llama.cpp/
    .flake8
    train-text-from-scratch
    k_quants.c
    ggml.o
    .gitignore
    ggml-mpi.h
    quantize-stats
    grammar-parser.o
    server
    .editorconfig
    SHA256SUMS
    common.o
    ggml-cuda.cu
    .dockerignore
    k_quants.h
    ggml-cuda.h
    ggml-alloc.h
    llama-util.h
    ggml-metal.metal
    ai.sh
    vdot
    quantize
    ggml-metal.h
    convert-pth-to-ggml.py
    .clang-tidy
    simple
    llama.o
    Package.swift
    console.o
    ggml-alloc.c
    build-info.h
    flake.nix
    embd-input-test
    ggml-mpi.c
    ggml-alloc.o
    ggml.h
    .ecrc
    llama.cpp
    CMakeLists.txt
    k_quants.o
    ggml-opencl.h
    ggml-opencl.cpp
    main
    requirements.txt
    Makefile
    .pre-commit-config.yaml
    convert-lora-to-ggml.py
    embedding
    flake.lock
    README.md
    libembdinput.so
    perplexity
    llama.h
    ggml-metal.m
    build.zig
    ggml.c
    LICENSE
    convert.py
    grammars/
        japanese.gbnf
        list.gbnf
        arithmetic.gbnf
        json.gbnf
        chess.gbnf
    prompts/
        dan-modified.txt
        chat-with-vicuna-v0.txt
        chat.txt
        reason-act.txt
        dan.txt
        alpaca.txt
        chat-with-bob.txt
        chat-with-vicuna-v1.txt
    .devops/
        full.Dockerfile
        tools.sh
        full-cuda.Dockerfile
        main-cuda.Dockerfile
        main.Dockerfile
    .git/
        packed-refs
        index
        config
        description
        HEAD
        info/
            exclude
        hooks/
            pre-receive.sample
            applypatch-msg.sample
            pre-commit.sample
            update.sample
            commit-msg.sample
            post-update.sample
            pre-applypatch.sample
            pre-push.sample
            push-to-checkout.sample
            fsmonitor-watchman.sample
            pre-merge-commit.sample
            prepare-commit-msg.sample
            pre-rebase.sample
        objects/
            info/
            pack/
                pack-30e7770f72a7c92a18bfb046518e6c47be51a028.pack
                pack-30e7770f72a7c92a18bfb046518e6c47be51a028.idx
        refs/
            remotes/
                origin/
                    HEAD
            heads/
                master
            tags/
        branches/
        logs/
            HEAD
            refs/
                remotes/
                    origin/
                        HEAD
                heads/
                    master
    models/
        ggml-vocab.bin
        7B/
            ggml-model.bin
    pocs/
        CMakeLists.txt
        vdot/
            CMakeLists.txt
            vdot.cpp
            q8dot.cpp
    .github/
        workflows/
            editorconfig.yml
            tidy-post.yml
            tidy-review.yml
            build.yml
            docker.yml
        ISSUE_TEMPLATE/
            custom.md
    media/
        llama0-banner.png
        llama-leader.jpeg
        llama0-logo.png
        llama1-banner.png
        llama1-logo.png
    spm-headers/
        ggml.h
        llama.h
    ci/
        README.md
        run.sh
    examples/
        llama2-13b.sh
        reason-act.sh
        gpt4all.sh
        chat-13B.bat
        chat.sh
        Miku.sh
        grammar-parser.cpp
        common.h
        chat-persistent.sh
        json-schema-to-grammar.py
        CMakeLists.txt
        grammar-parser.h
        chat-vicuna.sh
        llama2.sh
        make-ggml.py
        chat-13B.sh
        common.cpp
        alpaca.sh
        console.cpp
        llm.vim
        console.h
        server-llama2-13B.sh
        train-text-from-scratch/
            CMakeLists.txt
            train-text-from-scratch.cpp
            README.md
        quantize-stats/
            quantize-stats.cpp
            CMakeLists.txt
        server/
            json.hpp
            index.js.hpp
            chat.sh
            CMakeLists.txt
            deps.sh
            index.html.hpp
            api_like_OAI.py
            chat-llama2.sh
            completion.js.hpp
            httplib.h
            chat.mjs
            README.md
            server.cpp
            public/
                completion.js
                index.js
                index.html
        baby-llama/
            CMakeLists.txt
            baby-llama.cpp
        quantize/
            CMakeLists.txt
            quantize.cpp
            README.md
        simple/
            CMakeLists.txt
            simple.cpp
        benchmark/
            benchmark-matmult.cpp
            CMakeLists.txt
        save-load-state/
            CMakeLists.txt
            save-load-state.cpp
        embd-input/
            .gitignore
            embd_input.py
            minigpt4.py
            llava.py
            embd-input-test.cpp
            panda_gpt.py
            CMakeLists.txt
            embd-input.h
            embd-input-lib.cpp
            README.md
        main/
            main.cpp
            CMakeLists.txt
            README.md
        metal/
            metal.cpp
            CMakeLists.txt
        jeopardy/
            questions.txt
            jeopardy.sh
            qasheet.csv
            graph.py
            README.md
        embedding/
            CMakeLists.txt
            embedding.cpp
            README.md
        perplexity/
            perplexity.cpp
            CMakeLists.txt
            README.md
    scripts/
        build-info.sh
        sync-ggml.sh
        verify-checksum-models.py
        build-info.h.in
        ppl-run-all.sh
        build-info.cmake
        perf-run-all.sh
    docs/
        BLIS.md
        token_generation_performance_tips.md
    tests/
        test-sampling.cpp
        test-quantize-perf.cpp
        test-grad0.cpp
        CMakeLists.txt
        test-opt.cpp
        test-quantize-fns.cpp
        test-double-float.cpp
        test-tokenizer-0.cpp
